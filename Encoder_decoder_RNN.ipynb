{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMP1I7Xg3LmU"
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "\n",
    "# import files on google colab\n",
    "# from google.colab import files\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNrsb6tH3Rte"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# import files on google colab\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLmNCoxBoTHR"
   },
   "source": [
    "# **Helper class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-RYaIvy3Sbn"
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    \"\"\"\n",
    "    Helper class for creating dictionaries for languages\n",
    "    \"\"\"\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {'SOS':0,'EOS':1,'PAD':2}\n",
    "        self.index2word = {0:'SOS',1:'EOS',2:'PAD'}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 3\n",
    "\n",
    "    def add_sentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "            \n",
    "    def add_word(self,word):\n",
    "        # check if the word has appeared before\n",
    "        if word not in self.word2index:\n",
    "            # word to index at index (n_words)\n",
    "            self.word2index[word] = self.n_words\n",
    "            \n",
    "            # index (n_words) to word\n",
    "            self.index2word[self.n_words] = word\n",
    "            \n",
    "            # word count is set to 1\n",
    "            self.word2count[word] = 1\n",
    "            \n",
    "            # numbers of unique words increases by 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEHaKXZZ3XEO"
   },
   "outputs": [],
   "source": [
    "def read_Lang(reverse=False):\n",
    "    # open the file in the directory\n",
    "    # This is the only class that is language specific\n",
    "    \n",
    "    # Reads chinese to english files, the first line is English and second line is Chinese\n",
    "    f = open(\"cmn-eng.txt\",encoding='utf-8')\n",
    "    \n",
    "    # read lines in the file\n",
    "    lines = f.readlines()\n",
    "    lines = [line.rstrip().split('\\t')[0:2] for line in lines]\n",
    "    \n",
    "    # add all the lower case alphabetical letters into Chinese dictionary\n",
    "    alph = string.ascii_lowercase\n",
    "    alph = [s for s in alph]\n",
    "    alph = \" \".join(alph)\n",
    "\n",
    "    # close the file\n",
    "    f.close()\n",
    "    \n",
    "    if reverse:\n",
    "        lines = [list(reversed(line)) for line in lines]\n",
    "        \n",
    "        # Input is Chinese\n",
    "        input_ = [re.sub(r\" \",\"\",line[0]) for line in lines]\n",
    "        input_ = [[word for word in line] for line in input_]\n",
    "        input_ = [\" \".join(line) for line in input_]\n",
    "        input_ = [line.lower() for line in input_]\n",
    "        input_.append(alph)\n",
    "        \n",
    "        # Output is English\n",
    "        output_ = [re.sub(r\"([.!?])\",r\" \\1\",line[1]) for line in lines]\n",
    "        output_ =  [re.sub(r\"[^a-zA-Z.!?]+\", r\" \", line) for line in output_]\n",
    "        output_ = [s.lower() for s in output_]\n",
    "        \n",
    "        # Combine the pairs\n",
    "        pairs = [[i,o] for i,o in zip(input_,output_)]\n",
    "        input_class = Lang('cmn')\n",
    "        output_class = Lang('eng')\n",
    "    else:\n",
    "        # input is English\n",
    "        input_ = [re.sub(r\"([.!?])\",r\" \\1\",line[0]) for line in lines]\n",
    "        input_ =  [re.sub(r\"[^a-zA-Z.!?]+\", r\" \", line) for line in input_]\n",
    "        input_ = [s.lower() for s in input_]\n",
    "        \n",
    "        # output is Chinese\n",
    "        output_ = [re.sub(r\" \",\"\",line[1]) for line in lines]\n",
    "        output_ = [[word for word in line] for line in output_]\n",
    "        output_ = [\" \".join(line) for line in output_]\n",
    "        output_ = [line.lower() for line in output_]\n",
    "        output_.append(alph)\n",
    "        \n",
    "        # Combine the pairs\n",
    "        pairs = [[i,o] for i,o in zip(input_,output_)]\n",
    "        input_class = Lang('eng')\n",
    "        output_class = Lang('cmn')\n",
    "    \n",
    "    \n",
    "    for i in range(len(input_)):\n",
    "        input_class.add_sentence(input_[i])\n",
    "\n",
    "    for j in range(len(output_)):\n",
    "        output_class.add_sentence(output_[j])\n",
    "        \n",
    "    return input_class,output_class,pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecwxU6R93X6H"
   },
   "outputs": [],
   "source": [
    "class language_loader(Dataset):\n",
    "    def __init__(self,pairs,input_lang,output_lang,device):\n",
    "        self.pairs = pairs\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "\n",
    "        # find the length of sentences of the input and output sentence\n",
    "        length_in = [len(pair[0]) for pair in self.pairs]\n",
    "        length_out = [len(pair[1]) for pair in self.pairs]\n",
    "\n",
    "        # find the maximum length of the input and output sentence\n",
    "        self.in_max = max(length_in)\n",
    "        self.out_max = max(length_out)\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        input_s = pair[0].split(\" \")\n",
    "        input_s = input_s + ['EOS']\n",
    "        input_length = torch.LongTensor([len(input_s)])\n",
    "        \n",
    "        output_s = pair[1].split(\" \")\n",
    "        output_s = ['SOS'] + output_s + ['EOS']\n",
    "        output_length = torch.LongTensor([len(output_s)])\n",
    "        \n",
    "        src_pad_idx = self.input_lang.word2index['PAD']\n",
    "        trg_pad_idx = self.input_lang.word2index['PAD']\n",
    "        \n",
    "        input_tensor = torch.ones(self.in_max)*src_pad_idx\n",
    "        output_tensor = torch.ones(self.out_max)*trg_pad_idx\n",
    "        \n",
    "        for i in range(len(input_s)):\n",
    "            word = input_s[i]\n",
    "            input_tensor[i] = self.input_lang.word2index[word]\n",
    "        \n",
    "        for j in range(len(output_s)):\n",
    "            word = output_s[j]\n",
    "            output_tensor[j] = self.output_lang.word2index[word]\n",
    "\n",
    "        return input_tensor.long().to(self.device),output_tensor.long().to(self.device),input_length.to(self.device),output_length.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "Vx2_4Y433bY-",
    "outputId": "ce1339b0-6fac-4cb0-f501-89eec23f55a6"
   },
   "outputs": [],
   "source": [
    "input_lang,output_lang,pairs = read_Lang()\n",
    "l = language_loader(pairs,input_lang,output_lang,device)\n",
    "d = DataLoader(l,shuffle=True,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4v2BIAIiTwKA"
   },
   "source": [
    "## **Encoder RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc9c1-6wTyeg"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(torch.nn.Module):\n",
    "    def __init__(self,input_size,embedded_size,hidden_size,device,drop_p=0.1):\n",
    "        \"\"\"\n",
    "        inputs: \n",
    "        input_size: the size of the dictionary of the input language\n",
    "        hidden_size: hyper-parameter that represents the hidden state length of the model\n",
    "        device: the device that this model is operating on: either \"cpu\" or \"cuda\"\n",
    "        drop_p: dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedded_size = embedded_size\n",
    "        self.drop_p = drop_p\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(self.input_size, self.embedded_size)\n",
    "        self.rnn = torch.nn.GRU(self.embedded_size,self.hidden_size,bidirectional=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(self.hidden_size*2,self.hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(p=self.drop_p)\n",
    "        \n",
    "    def forward(self,input_t,src_len):\n",
    "        \"\"\"\n",
    "        input_t: a tensor of type Long that passes in the indices of the embedded dictionary\n",
    "                 of shape (src_max_len,batch_size)\n",
    "        \n",
    "        h0: a tensor of size (num_layers*2,batch_size,self.hidden_size) as we are performing bidirectional operation\n",
    "        \"\"\"\n",
    "        batch_size = input_t.shape[1]\n",
    "        \n",
    "        \n",
    "        # embedded of shape (src_len, batch_size, embedded)\n",
    "        embedded = self.dropout(self.embedding(input_t))\n",
    "        \n",
    "        packed_embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
    "        # hidden is of shape (num_layers * num_directions, batch, hidden_size)\n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "        \n",
    "        # encoder_outputs = [src len, batch_size, num_direction* embed dim ]\n",
    "        encoder_outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        # output has shape (src_len,batch_size,num_direction*hidden_size) and is the compilation of all the hidden state\n",
    "        # in the network\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "\n",
    "        return encoder_outputs,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nBLqwRXEL1I"
   },
   "outputs": [],
   "source": [
    "in_ = torch.tensor([[1,2,5],[2,3,6],[10,4,3]])\n",
    "_len = torch.tensor([2,2,1])\n",
    "Embed_dim = 30\n",
    "input_size = 20\n",
    "hidden_size = 40\n",
    "E = EncoderRNN(input_size,Embed_dim,hidden_size,drop_p=0.1,device=device)\n",
    "\n",
    "encoder_outputs,h = E(in_,_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K36-FEx1T6Fk"
   },
   "source": [
    "# **Attention Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ASQNjOGT8hY"
   },
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self,hidden_size,device):\n",
    "        \"\"\"\n",
    "        hidden_size: the hidden layer size\n",
    "        device: the device this model is operating on\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "\n",
    "        self.convh0 = torch.nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.attn = torch.nn.Linear((self.hidden_size* 2)+self.hidden_size, self.hidden_size)\n",
    "        self.v = torch.nn.Linear(self.hidden_size, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs,mask=None):\n",
    "        #h0 = [batch_size,hid dim]\n",
    "        #encoder_outputs = [src len, batch_size, enc hid dim * 2]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        batch_size =  hidden.shape[0]      \n",
    "        \n",
    "        # h0 = [batch_size, src len, hid dim]\n",
    "        hidden =  hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        #encoder_outputs = [batch_size, src len, hid dim * 2]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        # energy has shape (batch_size,src len,hid dim)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden,encoder_outputs),dim=2)))\n",
    "\n",
    "        # attention has shape(batch_size,src len,1)\n",
    "        attention = self.v(energy)\n",
    "\n",
    "        # attention has shape (batch_size,src len)\n",
    "        attention = attention.squeeze(2)\n",
    "        \n",
    "        # mask should be shape shape (batch_size, src len)\n",
    "        if mask !=  None:\n",
    "            attention = attention.masked_fill(mask == 0,-1e10)\n",
    "        \n",
    "        attention = torch.nn.functional.softmax(attention, dim=1)\n",
    "        \n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ox0LLN1V-kEf",
    "outputId": "2fb96da5-bd14-4783-a08c-dbf03dd72c70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5132, 0.4868],\n",
       "        [0.4971, 0.5029],\n",
       "        [0.5097, 0.4903]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Attention(hidden_size,device)\n",
    "a(h,encoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuSRYV6lUTVK"
   },
   "source": [
    "# **Decoder RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnVwVDZuUU3Y"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, output_size, embedded_size,hidden_size,device,drop_p=0.1):\n",
    "        \"\"\"\n",
    "        output_size: the size of the dictionary of the output language\n",
    "        \n",
    "        hidden_size: hyper-parameter that represents the hidden state length of the model\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size        \n",
    "        self.embedded_size = embedded_size\n",
    "        self.drop_p = drop_p\n",
    "\n",
    "\n",
    "        self.attention = Attention(self.hidden_size,device)\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(output_size,embedded_size)\n",
    "        \n",
    "        # input is context_vec concatenated with embedded, hidden is of size (1,1,hid dem)\n",
    "        self.rnn = torch.nn.GRU(self.hidden_size*2+self.embedded_size,self.hidden_size)\n",
    "        \n",
    "        # input incorporates (out from GRU, context_vec,embedded)\n",
    "        self.out = torch.nn.Linear(self.hidden_size*3+self.embedded_size,self.output_size)\n",
    "        self.dropout = torch.nn.Dropout(self.drop_p)\n",
    "        \n",
    "    def forward(self,input_vec,hidden,encoder_outputs,mask=None):\n",
    "        \"\"\"\n",
    "        input_vec: a vector of type torch.Long that is the index of the word being passed in (meant to be passed in with\n",
    "        # shape (1,batch_size))\n",
    "        \n",
    "        hidden: of shape [batch_size, hid dim]\n",
    "        \n",
    "        encoder_outputs: in the shape of (src_len,batch_size,hid dim*2) from bidirectional RNN encoder\n",
    "        \"\"\"\n",
    "        # number of batch_size passed in\n",
    "        batch_size = input_vec.shape[1]\n",
    "\n",
    "        # trg_len is 1 in the case for decoder as we pass it in one at a time\n",
    "        trg_len = input_vec.shape[0]\n",
    "        \n",
    "        # embedded has shape (trg_len,batch_size,embedded size)\n",
    "        embedded = self.dropout(self.embedding(input_vec))\n",
    "\n",
    "        # a has shape (batch_size,src_len)\n",
    "        a = self.attention(hidden,encoder_outputs,mask=mask)\n",
    "        \n",
    "        # a now has shape (batch_size,1,src_len)\n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        # encoder_outputs now has shape (batch_size,src_len,hid dim*2)\n",
    "        encoder_outputs = encoder_outputs.permute(1,0,2)\n",
    "        \n",
    "        # find the weighted output of the attention network (batch_size,1,hid dim*2)\n",
    "        context_vec = torch.bmm(a,encoder_outputs)\n",
    "        \n",
    "        \n",
    "        # context_vec has shape (trg len, batch_size,hid dim*2)\n",
    "        context_vec = context_vec.permute(1,0,2)\n",
    "        \n",
    "        # find the input to the decoder of shape (trg_len,batch_size,hid dim*2 + embedded dim)\n",
    "        decoder_input = torch.cat((embedded,context_vec),dim=2)\n",
    "        \n",
    "        \n",
    "        # out is (1,batch_size,hid dim*num_directions)\n",
    "        # h0 is (num_layers,batch_size,hid dim)\n",
    "        \n",
    "        out,hidden = self.rnn(decoder_input,hidden.unsqueeze(0))\n",
    "        \n",
    "        # embedded of shape (batch_size,embedded size)\n",
    "        embedded = embedded.squeeze(0)\n",
    "        # out is of shape (batch_size, hid dim)\n",
    "        out = out.squeeze(0)\n",
    "        # context_vec is of shape (batch_size,hid dim*2)\n",
    "        context_vec = context_vec.squeeze(0)\n",
    "        \n",
    "        \n",
    "        # out is of shape (batch_size,self.output_size)\n",
    "        out = self.out(torch.cat((out,context_vec,embedded),dim=1))\n",
    "        \n",
    "        return out, hidden.squeeze(0),a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1G1ciQ6W_DUL"
   },
   "outputs": [],
   "source": [
    "output_size=100\n",
    "embedded_size=50\n",
    "decoder = DecoderRNN(output_size,embedded_size,hidden_size,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HHEhp9WZUf-U"
   },
   "source": [
    "# **NMT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmzuKFPWUhbX"
   },
   "outputs": [],
   "source": [
    "class NMT(torch.nn.Module):\n",
    "    def __init__(self,hidden_size,embedded_size,input_lang,output_lang,device,drop_p=0.1):\n",
    "        \"\"\"\n",
    "        hidden_size: size of the hidden layer\n",
    "        embedded_size: size of the embedding \n",
    "        input_lang: input language object\n",
    "        output_lang: output language object\n",
    "        device: the device this model is operating on\n",
    "        drop_p: the drop out probability of the drop out layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedded_size = embedded_size\n",
    "        self.drop_p = drop_p\n",
    "\n",
    "\n",
    "        self.input_size = self.input_lang.n_words\n",
    "        self.output_size = self.output_lang.n_words\n",
    "        \n",
    "        self.SRC_PAD_IDX = self.input_lang.word2index['PAD']\n",
    "        self.TRG_PAD_IDX = self.output_lang.word2index['PAD']\n",
    "        \n",
    "        self.encoder = EncoderRNN(self.input_size,self.embedded_size,self.hidden_size,device=device,drop_p=self.drop_p)\n",
    "        self.decoder = DecoderRNN(self.output_size,self.embedded_size,self.hidden_size,device=device,drop_p=self.drop_p)\n",
    "        \n",
    "        self.loss = torch.nn.CrossEntropyLoss(ignore_index=self.TRG_PAD_IDX)\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "    def mask(self,input_t):\n",
    "        mask = (input_t != self.SRC_PAD_IDX).permute(1,0)\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def forward(self,data,teacher_enforce=0.5):\n",
    "        \"\"\"\n",
    "        data contains the following info: \n",
    "        input_t: of shape (batch_size,src len)\n",
    "        output_t: of shape (batch_size,trg len)\n",
    "        src_len: of shape (batch_size, 1) that contains the length of all the src sentences\n",
    "        trg_len: of shape (batch_size, 1) that contains the length of all the trg sentences\n",
    "        \"\"\" \n",
    "        input_t,output_t,src_len,trg_len = data\n",
    "        src_len = src_len.flatten()\n",
    "        src_len = src_len.long()\n",
    "        src_idx = torch.argsort(src_len,descending=True)\n",
    "\n",
    "        # find the maximum length of the input and output of this batch\n",
    "        max_in = torch.max(src_len)\n",
    "        max_out = torch.max(trg_len.flatten())\n",
    "        \n",
    "\n",
    "        # input_t and output_t are now of shape (src len, batch_size), (trg len, batch_size)\n",
    "        input_t,output_t = input_t.permute(1,0),output_t.permute(1,0)\n",
    "        batch_size = input_t.shape[1]\n",
    "        input_t = input_t[:max_in,:]\n",
    "        input_t = input_t[:,src_idx]\n",
    "\n",
    "        output_t = output_t[:max_out,:]\n",
    "        output_t = output_t[:,src_idx]\n",
    "\n",
    "\n",
    "        src_len = src_len[src_idx]        \n",
    "        src_mask = self.mask(input_t)\n",
    "        \n",
    " \n",
    "        #### Encoder part ####        \n",
    "        # encoder outputs of shape (src_len,batch_size,hid dim*2), encoder_h0 of shape (batch_size,hid dim)\n",
    "        encoder_outputs,encoder_hidden = self.encoder(input_t,src_len)    \n",
    "        \n",
    "        #### Decoder part ##### \n",
    "        # define the decoder hidden state input of shape (batch_size,hid dim)\n",
    "        decoder_hidden = encoder_hidden\n",
    "  \n",
    "        # The 'SOS' token of shape (1,batch_size)\n",
    "        decoder_input = output_t[0].view(1,batch_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        outputs = torch.zeros(max_out, batch_size, self.output_size).to(self.device)\n",
    "\n",
    "\n",
    "        cum_loss = 0\n",
    "        for k in range(1,max_out):\n",
    "            # output (batch_size,output_dim), hidden (1,batch_size,hid dim)\n",
    "            output,decoder_hidden,_ = self.decoder(decoder_input,decoder_hidden,encoder_outputs,mask=src_mask)\n",
    "            \n",
    "            outputs[k] = output\n",
    "            \n",
    "            top1 = torch.argmax(output,dim=1).view(1,batch_size)\n",
    "            randnum = torch.rand(1)\n",
    "\n",
    "            # check whether or not to use teacher enforced learning\n",
    "            criteria = randnum < teacher_enforce\n",
    "            \n",
    "            decoder_input = output_t[k].unsqueeze(0) if criteria else top1\n",
    "\n",
    "        outputs = outputs[1:].view(-1, self.output_size)\n",
    "        output_t = output_t[1:].view(-1)    \n",
    "        loss = self.loss(outputs,output_t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnwwsuvuNx9y"
   },
   "source": [
    "# **Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Z_7QpqGNxIC"
   },
   "outputs": [],
   "source": [
    "def train(model,trainloader,optimizer,teacher_enforce=0.5):\n",
    "    clip = 1\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for data in trainloader:\n",
    "        # zero out gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "                \n",
    "        loss = model(data,teacher_enforce=teacher_enforce)            \n",
    "\n",
    "        # call backward on loss\n",
    "        loss.backward()\n",
    "                \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "                \n",
    "        # perform gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss/len(trainloader)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nF78uSFeOpfW"
   },
   "source": [
    "# **Evaluation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljrm0NbaOtqW"
   },
   "outputs": [],
   "source": [
    "def evaluation(model,testloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        for data in testloader:\n",
    "            loss = model(data,teacher_enforce=0)\n",
    "            running_loss += loss.item()\n",
    "                \n",
    "            \n",
    "        return running_loss/len(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khidf3xJQWT_"
   },
   "source": [
    "# **Translate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_9StnP1QYsM"
   },
   "outputs": [],
   "source": [
    "def translate(model,input_,device,maxIter=100):\n",
    "    input_ = input_.lower()\n",
    "    input_ = re.sub(r\"([.!?])\",r\" \\1\",input_)\n",
    "    input_ =  re.sub(r\"[^a-zA-Z.!?]+\", r\" \",input_)\n",
    "    \n",
    "    input_s = input_.split(\" \")\n",
    "    input_s = input_s + ['EOS']    \n",
    "    input_t = torch.zeros(len(input_s),1).to(device)\n",
    "    for i in range(len(input_s)):\n",
    "        idx_i = model.input_lang.word2index[input_s[i]]\n",
    "        input_t[i,:] = idx_i\n",
    "        \n",
    "        \n",
    "    input_t = input_t.long()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        src_len = torch.LongTensor([len(input_s)]).to(device)\n",
    "        encoder_outputs,encoder_hidden = model.encoder(input_t,src_len)    \n",
    "        \n",
    "        # define the decoder hidden state input of shape (num_layers,1,hid dim)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # the first word passed into the decoder network is the SOS\n",
    "        decoder_input = model.output_lang.word2index['SOS']\n",
    "        decoder_input = torch.LongTensor([[decoder_input]]).to(device)\n",
    "        word = []\n",
    "            \n",
    "        iter_ = 0\n",
    "        attention = []\n",
    "            \n",
    "        while True:\n",
    "            if iter_ > maxIter:\n",
    "                print(\"Not converged\")\n",
    "                break\n",
    "            output,decoder_hidden,att = model.decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            attention.append(att.flatten())\n",
    "                \n",
    "            # find the top scoring candidate\n",
    "            top1 = torch.argmax(output,dim=1)\n",
    "           \n",
    "            # find the current token corresponding to the top scoring candiate\n",
    "            curr_token = model.output_lang.index2word[top1.item()]\n",
    "\n",
    "            # update decoder output to the top candidate\n",
    "            decoder_input = top1.view(1,1)\n",
    "            if curr_token == 'EOS':\n",
    "                break\n",
    "            word.append(curr_token)\n",
    "            \n",
    "            iter_ +=1\n",
    "        if model.output_lang.name == 'eng':\n",
    "            word = \" \".join(word)\n",
    "        else:\n",
    "            word = \"\".join(word)\n",
    "    return word,attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkdcSBqZQ6Qn"
   },
   "source": [
    "# **Training Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cgXK8osVNnX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "input_class,output_class,pairs = read_Lang()\n",
    "pairs = np.array(pairs)\n",
    "\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDED_SIZE = 256\n",
    "INPUT_LANG = input_class\n",
    "OUTPUT_LANG = output_class\n",
    "DROP_P = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ETFmkB5SNYB"
   },
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "teacher_enforce = 0.5\n",
    "kfold_train_l = []\n",
    "kfold_test_l = []\n",
    "\n",
    "k_split_num = 1\n",
    "best_loss = float('inf')\n",
    "\n",
    "for train_idx, test_idx in kf.split(pairs):\n",
    "  train_pairs,test_pairs = pairs[train_idx],pairs[test_idx]\n",
    "\n",
    "  train_data = language_loader(train_pairs,input_class,output_class,device=device)\n",
    "  trainloader = DataLoader(train_data,batch_size=128,shuffle=True)\n",
    "\n",
    "  test_data = language_loader(test_pairs,input_class,output_class,device=device)\n",
    "  testloader = DataLoader(test_data,batch_size=128)\n",
    "\n",
    "  train_loss_vec = []\n",
    "  test_loss_vec = []\n",
    "\n",
    "  model = NMT(HIDDEN_SIZE,EMBEDDED_SIZE,INPUT_LANG,OUTPUT_LANG,drop_p=DROP_P,device=device)\n",
    "  model = model.to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "  for e in range(EPOCH):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss = train(model,trainloader,optimizer,teacher_enforce=teacher_enforce)\n",
    "    test_loss = evaluation(model,testloader)\n",
    "\n",
    "    train_loss_vec.append(train_loss)\n",
    "    test_loss_vec.append(test_loss)\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(\"At {0:d} validation, iteration {1:d}, the train loss is {2:.3f} and test loss is {3:.3f},time it takes is {4:.3f}\".format(k_split_num,e+1,train_loss,test_loss,elapsed))\n",
    "\n",
    "  if test_loss < best_loss:\n",
    "    torch.save(model.state_dict(), \"NMT_model_{}.pt\".format(k_split_num))\n",
    "  k_split_num += 1\n",
    "\n",
    "  kfold_train_l.append(train_loss_vec)\n",
    "  kfold_test_l.append(test_loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QJM_T2O5RbPK",
    "outputId": "b52b079d-ef6f-481a-e2c0-d85ece267dbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMT(HIDDEN_SIZE,EMBEDDED_SIZE,INPUT_LANG,OUTPUT_LANG,drop_p=DROP_P,device=device)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"NMT_model_2.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7A_JFbpvFtl"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def bleu_score(ref,can,n_gram=4):    \n",
    "    if n_gram==4:    # 4-gram\n",
    "        weights=(0.25,0.25,0.25,0.25)\n",
    "    elif n_gram==3:  # 3-gram\n",
    "        weights=(0.33,0.33,0.33,0)\n",
    "    elif n_gram==2:  # 2-gram\n",
    "        weights=(0.5,0.5,0,0)        \n",
    "    elif n_gram==1:  # 1-gram\n",
    "        weights=(0.5,0.5,0,0)    \n",
    "    else:\n",
    "        print(\"wrong n_gram\")\n",
    "        return 0\n",
    "    return sentence_bleu(ref, can, weights)*100\n",
    "\n",
    "def ref_transform(ref):    \n",
    "    ref=re.sub(r\"([，；:。？、！])\",r\" \",ref)\n",
    "    ref=ref.split()\n",
    "\n",
    "    n_blank=0\n",
    "    for i in range(len(ref)):\n",
    "        if ref[i]=='':\n",
    "            n_blank=n_blank+1\n",
    "    for i in range(n_blank):\n",
    "        ref.remove('')\n",
    "    return ref\n",
    "\n",
    "def can_transform(result):\n",
    "    result=re.sub(r\"([，；:。？、！])\",r\" \",result)\n",
    "    can=[]\n",
    "    for i in range(len(result)):\n",
    "        if result[i]!=' ':\n",
    "            can.append(result[i])\n",
    "    return can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5fGPo9ftrMC"
   },
   "outputs": [],
   "source": [
    "score=0\n",
    "n_count=0\n",
    "for i in range(len(pairs)):\n",
    "    ref=pairs[i][1]\n",
    "    ref=ref_transform(ref)\n",
    "    if len(ref)>7:         # only evaluate sentences with 8 or more Chinese characters\n",
    "        result=translate(model,pairs[i][0],device)[0]\n",
    "        can=can_transform(result)\n",
    "        temp=bleu_score([ref],can,4)\n",
    "        score=score+temp\n",
    "        n_count=n_count+1\n",
    "    #if i%1000==999:\n",
    "        #print(i+1)\n",
    "print(n_count)\n",
    "print(score/n_count)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NMT_batch",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
